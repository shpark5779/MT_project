{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11061e03-de10-4b15-ba5d-1e5f2f613983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/KYUH_data/90\n"
     ]
    }
   ],
   "source": [
    "cd \"/tf/KYUH_data/90/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a521b5-9da8-4f41-a784-ef824ea3d901",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar -xvzf pandas-2.2.2.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa4fa0c-1656-44c5-8f1c-68f5c9a50f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --no-index --find-link=./ pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dfdb96-164d-45bf-a105-73662903b922",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python Preprocessing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bc5fe7-f4a0-4cca-9118-732324bf0cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.abspath(\"03b9c09d-9018-4104-a249-2ec9c471dbf0.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaeaba8-2d96-4c58-a6b7-d9e07808683c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = os.listdir(\"labeled-images/lower-gi-tract/pathological-findings\")+os.listdir(\"labeled-images/upper-gi-tract/pathological-findings\")\n",
    "print(set(class_list))\n",
    "a = ['barretts', 'ulcerative-colitis-grade-3']\n",
    "\n",
    "if 'ulcerative' in a[1]:\n",
    "    print('pass')\n",
    "\n",
    "a = np.arange(1,8)\n",
    "print(a)\n",
    "a[2:2+3] = 10\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ce3ca2-cbd8-4ab7-9891-70d95f034ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = cv2.imread(\"LIMUC/train_and_validation_sets/Mayo 3/UC_patient_97_9.bmp\")\n",
    "print(a)\n",
    "# plt.imshow(a)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d27a679-11f5-4ffc-8364-aae87bec859f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mayo 3', 'Mayo 2', 'Mayo 1', 'Mayo 0']\n",
      "Mayo 3\n",
      "745\n",
      "2980\n",
      "Mayo 2\n",
      "1077\n",
      "5134\n",
      "Mayo 1\n",
      "2588\n",
      "7722\n",
      "Mayo 0\n",
      "5180\n",
      "12902\n",
      "100/12902 images Done.\n",
      "200/12902 images Done.\n",
      "300/12902 images Done.\n",
      "400/12902 images Done.\n",
      "500/12902 images Done.\n",
      "600/12902 images Done.\n",
      "700/12902 images Done.\n",
      "800/12902 images Done.\n",
      "900/12902 images Done.\n",
      "1000/12902 images Done.\n",
      "1100/12902 images Done.\n",
      "1200/12902 images Done.\n",
      "1300/12902 images Done.\n",
      "1400/12902 images Done.\n",
      "1500/12902 images Done.\n",
      "1600/12902 images Done.\n",
      "1700/12902 images Done.\n",
      "1800/12902 images Done.\n",
      "1900/12902 images Done.\n",
      "2000/12902 images Done.\n",
      "2100/12902 images Done.\n",
      "2200/12902 images Done.\n",
      "2300/12902 images Done.\n",
      "2400/12902 images Done.\n",
      "2500/12902 images Done.\n",
      "2600/12902 images Done.\n",
      "2700/12902 images Done.\n",
      "2800/12902 images Done.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m file_name:\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m label \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMayo 3\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 44\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtv_path\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m         f \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mfilter2D(img, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, sharpen_f)\n\u001b[1;32m     46\u001b[0m         img_rr \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mrotate(img, cv2\u001b[38;5;241m.\u001b[39mROTATE_180)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# print(os.listdir(\"labeled-images/lower-gi-tract/pathological-findings\"))\n",
    "tv_class_list = os.listdir(\"LIMUC/train_and_validation_sets/\")\n",
    "tst_class_list = os.listdir(\"LIMUC/test_set/\")\n",
    "tv_path = \"LIMUC/train_and_validation_sets/\"\n",
    "tst_path = \"LIMUC/test_set/\"\n",
    "print(tv_class_list)\n",
    "NOI = 0\n",
    "for label in tv_class_list:\n",
    "    print(label)\n",
    "    LN = len(os.listdir(\"LIMUC/train_and_validation_sets/\"+label))\n",
    "    if label == 'Mayo 3':\n",
    "        NOI += (LN*4)\n",
    "    elif label == 'Mayo 2':\n",
    "        NOI += (LN*2)\n",
    "    else:\n",
    "        NOI += LN\n",
    "    print(LN)\n",
    "    print(NOI)\n",
    "\n",
    "patho_img_list = []\n",
    "name_label = []\n",
    "\n",
    "sharpen_f = np.array([[-1, -1, -1, -1, -1],\n",
    "                      [-1, 2, 2, 2, -1],\n",
    "                      [-1, 2, 9, 2, -1],\n",
    "                      [-1, 2, 2, 2, -1],\n",
    "                      [-1, -1, -1, -1, -1]])/9.0\n",
    "\n",
    "imgs = np.ndarray(shape=(NOI,288,352,3))\n",
    "labels = np.ndarray(shape=(NOI))\n",
    "\n",
    "i = 0\n",
    "L = 3\n",
    "for label in tv_class_list:\n",
    "    file_name = os.listdir(tv_path+label)\n",
    "    for file in file_name:\n",
    "        if label == 'Mayo 3':\n",
    "            img = cv2.imread(tv_path+label+'/'+file)\n",
    "            f = cv2.filter2D(img, -1, sharpen_f)\n",
    "            img_rr = cv2.rotate(img, cv2.ROTATE_180)\n",
    "            ff = cv2.filter2D(img_rr, -1, sharpen_f)\n",
    "            imgs[i] = img\n",
    "            imgs[i+1] = f\n",
    "            imgs[i+2] = img_rr\n",
    "            imgs[i+3] = ff\n",
    "            labels[i:i+4] = L\n",
    "            i+=4\n",
    "            if i % 100 == 0:\n",
    "                print(\"{0}/{1} images Done.\".format(i,len(labels)))\n",
    "        elif label == 'Mayo 2':\n",
    "            img = cv2.imread(tv_path+label+'/'+file)\n",
    "            f = cv2.filter2D(img, -1, sharpen_f)\n",
    "            imgs[i] = img\n",
    "            imgs[i+1] = f\n",
    "            labels[i:i+2] = L\n",
    "            i+=2\n",
    "            if i % 100 == 0:\n",
    "                print(\"{0}/{1} images Done.\".format(i,len(labels)))\n",
    "        else:\n",
    "            img = cv2.imread(tv_path+label+'/'+file)\n",
    "            labels[i] = L\n",
    "            i+=1\n",
    "            if i % 100 == 0:\n",
    "                print(\"{0}/{1} images Done.\".format(i,len(labels)))\n",
    "    L-=1\n",
    "    \n",
    "\n",
    "print(i)\n",
    "print(len(labels), np.unique(labels))\n",
    "print(labels)\n",
    "print(\"ALL images Done.\")\n",
    "np.save(\"npys/LUMIC_Train_imgs.npy\", imgs)\n",
    "np.save(\"npys/LUMIC_Train_labels.npy\", labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380ac82e-64cd-4482-863d-9482d0b1b187",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_______________________Hyper-Kvasir_________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2daf069-a2d8-419d-b2d2-bdf09acaf4e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# print(os.listdir(\"labeled-images/lower-gi-tract/pathological-findings\"))\n",
    "class_list = os.listdir(\"labeled-images/lower-gi-tract/pathological-findings\")+os.listdir(\"labeled-images/upper-gi-tract/pathological-findings\")\n",
    "file = open(\"labeled-images/image-labels.csv\", \"r\")\n",
    "print(file)\n",
    "gi_img_list = csv.reader(file)\n",
    "patho_img_list = []\n",
    "# patho_img_list = patho_img_list+[['a', '0']]+[['b', '1']]\n",
    "# print(patho_img_list)\n",
    "name_label = []\n",
    "\n",
    "sharpen_f = np.array([[-1, -1, -1, -1, -1],\n",
    "                      [-1, 2, 2, 2, -1],\n",
    "                      [-1, 2, 9, 2, -1],\n",
    "                      [-1, 2, 2, 2, -1],\n",
    "                      [-1, -1, -1, -1, -1]])/9.0\n",
    "\n",
    "# KYUH_data/90/labeled-images/lower-gi-tract/pathological-findings/ulcerative-colitis-grade-0-1\n",
    "imgs = np.ndarray(shape=(3294,256,256,3)) #2642-hemorrhoids(6)-94+(94*8)\n",
    "labels = np.ndarray(shape=(3294))\n",
    "# 2642\n",
    "i = 0\n",
    "for row in gi_img_list:\n",
    "    if 'pathological-findings' in row:\n",
    "        if 'Lower' in row[1]:\n",
    "            if 'ulcerative-colitis' in row[2]:\n",
    "                # print('filename', row[0], 'find', row[2])\n",
    "                img = cv2.imread('labeled-images/lower-gi-tract/pathological-findings/'+row[2]+'/'+row[0]+\".jpg\")\n",
    "                img = cv2.resize(img,(256,256), cv2.INTER_CUBIC)\n",
    "                imgs[i] = img\n",
    "                labels[i] = 0\n",
    "                if i % 100 == 0:\n",
    "                    print(\"{0}/{1} images Done.\".format(i,len(labels)))\n",
    "                i+=1\n",
    "            elif 'polyps' in row[2]:\n",
    "                # print('filename', row[0], 'find', row[2])\n",
    "                img = cv2.imread('labeled-images/lower-gi-tract/pathological-findings/'+row[2]+'/'+row[0]+\".jpg\")\n",
    "                img = cv2.resize(img,(256,256), cv2.INTER_CUBIC)\n",
    "                imgs[i] = img\n",
    "                labels[i] = 1\n",
    "                if i % 100 == 0:\n",
    "                    print(\"{0}/{1} images Done.\".format(i,len(labels)))\n",
    "                i+=1\n",
    "            elif 'hemorrhoids' in row[2]:\n",
    "                pass\n",
    "        elif 'Upper' in row[1]:\n",
    "            if 'esophagitis' in row[2]:\n",
    "                # print('filename', row[0], 'find', row[2])\n",
    "                img = cv2.imread('labeled-images/upper-gi-tract/pathological-findings/'+row[2]+'/'+row[0]+\".jpg\")\n",
    "                img = cv2.resize(img,(256,256), cv2.INTER_CUBIC)\n",
    "                imgs[i] = img\n",
    "                labels[i] = 2\n",
    "                if i % 100 == 0:\n",
    "                    print(\"{0}/{1} images Done.\".format(i,len(labels)))\n",
    "                i+=1\n",
    "            elif 'barretts' in row[2]:\n",
    "                # print('filename', row[0], 'find', row[2])\n",
    "                img = cv2.imread('labeled-images/upper-gi-tract/pathological-findings/'+row[2]+'/'+row[0]+\".jpg\")\n",
    "                img = cv2.resize(img,(256,256), cv2.INTER_CUBIC)\n",
    "                img_r = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
    "                img_rr = cv2.rotate(img, cv2.ROTATE_180)\n",
    "                img_rrr = cv2.rotate(img_rr, cv2.ROTATE_180)\n",
    "                f = cv2.filter2D(img, -1, sharpen_f)\n",
    "                f_r = cv2.filter2D(img_r, -1, sharpen_f)\n",
    "                f_rr = cv2.filter2D(img_rr, -1, sharpen_f)\n",
    "                f_rrr = cv2.filter2D(img_rrr, -1, sharpen_f)\n",
    "                imgs[i] = img\n",
    "                imgs[i+1] = img_r\n",
    "                imgs[i+2] = img_rr\n",
    "                imgs[i+3] = img_rrr\n",
    "                imgs[i+4] = f\n",
    "                imgs[i+5] = f_r\n",
    "                imgs[i+6] = f_rr\n",
    "                imgs[i+7] = f_rrr\n",
    "                labels[i:i+8] = 3\n",
    "                if i % 100 == 0:\n",
    "                    print(\"{0}/{1} images Done.\".format(i,len(labels)))\n",
    "                i+=8\n",
    "\n",
    "print(i)\n",
    "print(len(class_list))\n",
    "print(len(labels), np.unique(labels))\n",
    "print(labels)\n",
    "print(\"ALL images Done.\")\n",
    "np.save(\"npys/ForPretr_imgs.npy\", imgs)\n",
    "np.save(\"npys/ForPretr_labels.npy\", labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc88cc58-63df-422d-9569-30f942a9b074",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='labeled-images/image-labels.csv' mode='r' encoding='UTF-8'>\n",
      "0/3294 images Done.\n",
      "100/3294 images Done.\n",
      "200/3294 images Done.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [19], line 42\u001b[0m\n\u001b[1;32m     39\u001b[0m     i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpolyps\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m row[\u001b[38;5;241m2\u001b[39m]:\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# print('filename', row[0], 'find', row[2])\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabeled-images/lower-gi-tract/pathological-findings/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.jpg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(img,(\u001b[38;5;241m256\u001b[39m,\u001b[38;5;241m256\u001b[39m), cv2\u001b[38;5;241m.\u001b[39mINTER_CUBIC)\n\u001b[1;32m     44\u001b[0m     imgs[i] \u001b[38;5;241m=\u001b[39m img\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# print(os.listdir(\"labeled-images/lower-gi-tract/pathological-findings\"))\n",
    "class_list = os.listdir(\"labeled-images/lower-gi-tract/pathological-findings\")+os.listdir(\"labeled-images/upper-gi-tract/pathological-findings\")\n",
    "file = open(\"labeled-images/image-labels.csv\", \"r\")\n",
    "print(file)\n",
    "gi_img_list = csv.reader(file)\n",
    "patho_img_list = []\n",
    "# patho_img_list = patho_img_list+[['a', '0']]+[['b', '1']]\n",
    "# print(patho_img_list)\n",
    "name_label = []\n",
    "\n",
    "sharpen_f = np.array([[-1, -1, -1, -1, -1],\n",
    "                      [-1, 2, 2, 2, -1],\n",
    "                      [-1, 2, 9, 2, -1],\n",
    "                      [-1, 2, 2, 2, -1],\n",
    "                      [-1, -1, -1, -1, -1]])/9.0\n",
    "\n",
    "# KYUH_data/90/labeled-images/lower-gi-tract/pathological-findings/ulcerative-colitis-grade-0-1\n",
    "imgs = np.ndarray(shape=(3294,256,256,3)) #2642-hemorrhoids(6)-94+(94*8)\n",
    "labels = np.ndarray(shape=(3294))\n",
    "# 2642\n",
    "i = 0\n",
    "for row in gi_img_list:\n",
    "    if 'pathological-findings' in row:\n",
    "        if 'Lower' in row[1]:\n",
    "            if 'ulcerative-colitis' in row[2]:\n",
    "                # print('filename', row[0], 'find', row[2])\n",
    "                img = cv2.imread('labeled-images/lower-gi-tract/pathological-findings/'+row[2]+'/'+row[0]+\".jpg\")\n",
    "                img = cv2.resize(img,(256,256), cv2.INTER_CUBIC)\n",
    "                imgs[i] = img\n",
    "                labels[i] = 0\n",
    "                if i % 100 == 0:\n",
    "                    print(\"{0}/{1} images Done.\".format(i,len(labels)))\n",
    "                i+=1\n",
    "            elif 'polyps' in row[2]:\n",
    "                # print('filename', row[0], 'find', row[2])\n",
    "                img = cv2.imread('labeled-images/lower-gi-tract/pathological-findings/'+row[2]+'/'+row[0]+\".jpg\")\n",
    "                img = cv2.resize(img,(256,256), cv2.INTER_CUBIC)\n",
    "                imgs[i] = img\n",
    "                labels[i] = 1\n",
    "                if i % 100 == 0:\n",
    "                    print(\"{0}/{1} images Done.\".format(i,len(labels)))\n",
    "                i+=1\n",
    "            elif 'hemorrhoids' in row[2]:\n",
    "                pass\n",
    "        elif 'Upper' in row[1]:\n",
    "            if 'esophagitis' in row[2]:\n",
    "                # print('filename', row[0], 'find', row[2])\n",
    "                img = cv2.imread('labeled-images/upper-gi-tract/pathological-findings/'+row[2]+'/'+row[0]+\".jpg\")\n",
    "                img = cv2.resize(img,(256,256), cv2.INTER_CUBIC)\n",
    "                imgs[i] = img\n",
    "                labels[i] = 2\n",
    "                if i % 100 == 0:\n",
    "                    print(\"{0}/{1} images Done.\".format(i,len(labels)))\n",
    "                i+=1\n",
    "            elif 'barretts' in row[2]:\n",
    "                # print('filename', row[0], 'find', row[2])\n",
    "                img = cv2.imread('labeled-images/upper-gi-tract/pathological-findings/'+row[2]+'/'+row[0]+\".jpg\")\n",
    "                img = cv2.resize(img,(256,256), cv2.INTER_CUBIC)\n",
    "                labels[i] = 3\n",
    "                if i % 100 == 0:\n",
    "                    print(\"{0}/{1} images Done.\".format(i,len(labels)))\n",
    "                i+=1\n",
    "\n",
    "print(i)\n",
    "print(len(class_list))\n",
    "print(len(labels), np.unique(labels))\n",
    "print(labels)\n",
    "print(\"ALL images Done.\")\n",
    "np.save(\"npys/ForPretr_imgs.npy\", imgs)\n",
    "np.save(\"npys/ForPretr_labels.npy\", labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a787a1-3fbd-4925-b6b0-e39a294f38e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = cv2.imread(\"MT_0/c0_03_3b8d5663.jpg\")\n",
    "# contour_process(a)\n",
    "# MT_0/c0_21_a139dfa6.jpg\n",
    "# [[ 668  978]\n",
    "#  [ 668   99]\n",
    "#  [1555   99]\n",
    "#  [1555  978]]\n",
    "'''\n",
    "MT_0/c0_03_3b8d5663.jpg\n",
    "[[ 452,970],\n",
    " [ 452,91],\n",
    " [1338,91],\n",
    " [1338,970]]\n",
    "MT_0/c0_21_a139dfa6.jpg\n",
    " [[ 668,978],\n",
    " [ 668,99],\n",
    " [1555,99],\n",
    " [1555,978]]\n",
    "\n",
    " MT_0/c0_03_3b8d5663.jpg\n",
    "[[ 452  970]\n",
    " [ 452   91]\n",
    " [1338   91]\n",
    " [1338  970]]\n",
    "\n",
    " MT_0/c0_03_3b8d5663.jpg\n",
    "[[ 452  ,970],\n",
    " [ 452   ,91],\n",
    " [1338   ,91],\n",
    " [1338  ,970]]\n",
    "\n",
    "MT_0/c0_06_441c1caa.jpg\n",
    "[[ 665   ,92],\n",
    " [1552   ,92],\n",
    " [1552  ,709],\n",
    " [ 665  ,709]]\n",
    "\n",
    " MT_0/c0_01_b10fb137.jpg\n",
    "[[ 759  100]\n",
    " [1646  100]\n",
    " [1646  978]\n",
    " [ 759  978]]\n",
    "\n",
    " [[ 665,92],\n",
    " [1552,92],\n",
    " [1552,970],\n",
    " [ 665,970]]\n",
    "'''\n",
    "# hist, bins =np.histogram(a.flatten(), 256, [0,256])\n",
    "# cdf = hist.cumsum()\n",
    "# cdf_m = np.ma.masked_equal(cdf,0)\n",
    "# cdf_m = (cdf_m-cdf_m.min())*255/(cdf_m.max()-cdf_m.min())\n",
    "# cdf = np.ma.filled(cdf_m,0).astype('uint8')\n",
    "# img2 = cdf[a]\n",
    "# clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "# img2 = clahe.apply(a)\n",
    "# plt.imshow(a)\n",
    "# plt.show()\n",
    "# plt.imshow(img2)\n",
    "# plt.show()\n",
    "b =  [[ 452  ,970],\n",
    " [ 452   ,91],\n",
    " [1338   ,91],\n",
    " [1338  ,970]]\n",
    "print(b[3][1])\n",
    "#c = a[92:970,665:1552]\n",
    "print(np.min(b[1][1]),b[3][1],b[0][0],np.max(b[:][2]))\n",
    "c = a[np.min(b[1][1]):b[3][1],b[0][0]:np.max(b[:][2])]\n",
    "plt.imshow(c)\n",
    "plt.show()\n",
    "plt.imshow(a)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9b418c-3170-4b4a-a4d7-2670689354b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_________________________________________For MT Data__________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6221f363-1af2-4130-ab13-4937a5a56bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def histEQ(img):\n",
    "    hist, bins =np.histogram(img.flatten(), 256, [0,256])\n",
    "    cdf = hist.cumsum()\n",
    "    cdf_m = np.ma.masked_equal(cdf,0)\n",
    "    cdf_m = (cdf_m-cdf_m.min())*255/(cdf_m.max()-cdf_m.min())\n",
    "    cdf = np.ma.filled(cdf_m,0).astype('uint8')\n",
    "    img2 = cdf[img]\n",
    "    return img2\n",
    "\n",
    "\n",
    "def contour_process(Input,name):\n",
    "    copy = Input.copy()\n",
    "    rgb_img = cv2.cvtColor(Input, cv2.COLOR_BGR2RGB)\n",
    "    rgb_img = histEQ(rgb_img)\n",
    "    gr_img = cv2.cvtColor(Input, cv2.COLOR_BGR2GRAY)\n",
    "    ret, thr = cv2. threshold(gr_img, 25, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    contours1,_ =  cv2.findContours(thr, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    x_dis, y_dis, C_num = 0, 0, 0\n",
    "    for k in range(len(contours1)):\n",
    "        x,y,w,h = cv2.boundingRect(contours1[k])\n",
    "        # print(\"Number:\", k, \"x_dis: \", w-x, \"y_dis: \", h-y)\n",
    "        if x_dis<w:\n",
    "            if y_dis<h:\n",
    "                x_dis, y_dis = w-x, h-y\n",
    "                x_1, y_1, w_1, h_1 = x,y,w,h\n",
    "                C_num = k\n",
    "    stencil_r = np.zeros(Input.shape[:-1]).astype(np.uint8)\n",
    "    stencil_g = np.zeros(Input.shape[:-1]).astype(np.uint8)\n",
    "    stencil_b = np.zeros(Input.shape[:-1]).astype(np.uint8)\n",
    "    rect = cv2.minAreaRect(contours1[C_num])\n",
    "    box = cv2.boxPoints(rect)\n",
    "    box = np.int0(box)\n",
    "    # print(box)\n",
    "    a = cv2.drawContours(rgb_img, [box], -1, (0, 0, 255),10)\n",
    "    # plt.imshow(a)\n",
    "    # plt.show()\n",
    "\n",
    "    croped_img = copy[np.min(box[1][1]):box[3][1], box[0][0]:np.max(box[:][2])]\n",
    "    if np.abs(croped_img.shape[0]-croped_img.shape[1])>30:\n",
    "        print(name, croped_img.shape)\n",
    "    #print(croped_img.shape)\n",
    "    # plt.imshow(croped_img)\n",
    "    # plt.show()\n",
    "    rs_img = cv2.resize(croped_img,(256,256), cv2.INTER_CUBIC)\n",
    "    # plt.imshow(rs_img)\n",
    "    # plt.show()\n",
    "    return rs_img\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    D_path1, D_path2  = \"MT_0/\", \"MT_1/\"\n",
    "\n",
    "    mt0_list = os.listdir(D_path1)\n",
    "    mt1_list = os.listdir(D_path2)\n",
    "    j = 0\n",
    "    for file_name in mt0_list:\n",
    "        mt0_list[j]=\"MT_0/\"+file_name\n",
    "        j+=1\n",
    "    j = 0\n",
    "    for file_name in mt1_list:\n",
    "        mt1_list[j]=\"MT_1/\"+file_name\n",
    "        j+=1\n",
    "    print(mt0_list[0])\n",
    "    num_mt0 = len(mt0_list)\n",
    "    num_mt1 = len(mt1_list)\n",
    "\n",
    "    print(num_mt0, num_mt1)\n",
    "    imgs = np.ndarray(shape=(num_mt0+num_mt1,256,256,3))\n",
    "    labels = np.ndarray(shape=(num_mt0+num_mt1))\n",
    "    print(imgs.shape)\n",
    "    img_list = mt0_list+mt1_list\n",
    "    print(len(img_list))\n",
    "    print(\"_\"*30)\n",
    "    print(\"Create Img Dataset\")\n",
    "    print(\"_\"*30)\n",
    "    i = 0\n",
    "    a = list\n",
    "    for img_name in img_list:\n",
    "        img = cv2.imread(img_name)\n",
    "        # print(img_name)\n",
    "        pred_img = contour_process(img,img_name)\n",
    "        cv2.imwrite(\"Pred_imgs/\"+img_name, pred_img)\n",
    "        imgs[i] = pred_img\n",
    "\n",
    "        if i <= len(mt0_list):\n",
    "            labels[i] = 0\n",
    "            if i == len(mt0_list):\n",
    "                # print(i)\n",
    "                print(\"*\"*20, \"Convert\", \"*\"*20)\n",
    "        elif i > len(mt0_list): #KYUH_data/90/Pred_imgs/MT_0\n",
    "            labels[i] = 1\n",
    "        if i % 100 == 0:\n",
    "            print(\"{0}/{1} images Done.\".format(i,len(img_list)))\n",
    "        i+=1\n",
    "    print(np.unique(labels))\n",
    "    print(\"ALL images Done.\".format(i,len(img_list)))\n",
    "    np.save(\"npys/Total_imgs.npy\", imgs)\n",
    "    np.save(\"npys/Total_imgs_labels.npy\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296859ad-6553-46ab-a29e-0e751286f8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_path1, D_path2  = \"MT_0/\", \"MT_1/\"\n",
    "\n",
    "mt0_list = os.listdir(D_path1)\n",
    "mt1_list = os.listdir(D_path2)\n",
    "j = 0\n",
    "for file_name in mt0_list:\n",
    "    mt0_list[j]=\"MT_0/\"+file_name\n",
    "    j+=1\n",
    "j = 0\n",
    "for file_name in mt1_list:\n",
    "    mt1_list[j]=\"MT_1/\"+file_name\n",
    "    j+=1\n",
    "print(mt0_list[0])\n",
    "num_mt0 = len(mt0_list)\n",
    "num_mt1 = len(mt1_list)\n",
    "\n",
    "print(num_mt0, num_mt1)\n",
    "imgs = np.ndarray(shape=(num_mt0+num_mt1,256,256,3))\n",
    "labels = np.ndarray(shape=(num_mt0+num_mt1))\n",
    "print(imgs.shape)\n",
    "img_list = mt0_list+mt1_list\n",
    "print(len(img_list))\n",
    "print(\"_\"*30)\n",
    "print(\"Creat Img Dataset\")\n",
    "print(\"_\"*30)\n",
    "i = 0\n",
    "a = list\n",
    "for img_name in img_list:\n",
    "    # print(img_name)\n",
    "    img = cv2.imread(img_name)\n",
    "    pred_img = contour_process(img)\n",
    "    imgs[i] = pred_img\n",
    "    if i <= len(mt0_list):\n",
    "        labels[i] = 0\n",
    "        if i == len(mt0_list):\n",
    "            print(i)\n",
    "            print(\"*\"*20, \"Convert\", \"*\"*20)\n",
    "    elif i > len(mt0_list):\n",
    "        labels[i] = 1\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(\"{0}/{1} images Done.\".format(i,len(img_list)))\n",
    "    i+=1\n",
    "print(np.unique(labels))\n",
    "print(\"ALL images Done.\".format(i,len(img_list)))\n",
    "np.save(\"npys/Total_imgs.npy\", imgs)\n",
    "np.save(\"npys/Total_imgs_labels.npy\", labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cae3f42-fd14-4a86-a636-0269ccc6a0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#______________________ Creat npy ________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8e8dc1-f21d-4a16-9c19-8a2feda8d48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "img_data_path = \"npys/ForPretr_imgs.npy\"\n",
    "label_data_path= \"npys/ForPretr_labels.npy\"\n",
    "\n",
    "img_npy = np.load(img_data_path)\n",
    "label_npy = np.load(label_data_path)\n",
    "print(len(label_npy))\n",
    "img_rows = img_npy.shape[1]\n",
    "img_cols = img_npy.shape[2]\n",
    "\n",
    "train_img, val_img, train_label, val_label = train_test_split(img_npy, label_npy, test_size = 0.5, random_state=602625)\n",
    "test_img, val_img, test_label, val_label = train_test_split(val_img, val_label, test_size = 0.4, random_state=602625)\n",
    "\n",
    "np.save(\"npys/For_Pretraining/Train_imgs.npy\", train_img)\n",
    "np.save(\"npys/For_Pretraining/Train_labels.npy\", train_label)\n",
    "\n",
    "np.save(\"npys/For_Pretraining/Val_imgs.npy\", val_img)\n",
    "np.save(\"npys/For_Pretraining/Val_labels.npy\", val_label)\n",
    "\n",
    "np.save(\"npys/For_Pretraining/Test_imgs.npy\", test_img)\n",
    "np.save(\"npys/For_Pretraining/Test_labels.npy\", test_label)\n",
    "\n",
    "print(\"All Data is Ready to Train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b49aa49-7851-4e9f-9b8f-0eb7f96eb0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#________________________________Train________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a49201b8-5266-4ac2-aba2-aa0831d41694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/KYUH_data/90\n"
     ]
    }
   ],
   "source": [
    "cd \"/tf/KYUH_data/90/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eaf053d6-e282-4115-9dff-9b83acaf5348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************\n",
      "Loading Dataset\n",
      "******************************\n",
      "******************************\n",
      "Complete Load Dataset\n",
      "******************************\n",
      "(256, 256, 3)\n",
      "Train:  (3945, 256, 256, 3) Val:  (987, 256, 256, 3)\n",
      "0=  1668 1=  2277\n",
      "Weight for Classes 0: 1.18 Weight for Classes 1: 0.87\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 398s 24s/step - loss: 0.5250 - mean_absolute_error: 0.3452 - categorical_accuracy: 0.7376 - val_loss: 0.7248 - val_mean_absolute_error: 0.4719 - val_categorical_accuracy: 0.5755\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 390s 24s/step - loss: 0.2344 - mean_absolute_error: 0.1450 - categorical_accuracy: 0.9136 - val_loss: 1.6967 - val_mean_absolute_error: 0.4299 - val_categorical_accuracy: 0.5684\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 390s 24s/step - loss: 0.0811 - mean_absolute_error: 0.0486 - categorical_accuracy: 0.9691 - val_loss: 2.7219 - val_mean_absolute_error: 0.4233 - val_categorical_accuracy: 0.5755\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0698 - mean_absolute_error: 0.0397 - categorical_accuracy: 0.9749 Restoring model weights from the end of the best epoch: 1.\n",
      "16/16 [==============================] - 390s 24s/step - loss: 0.0698 - mean_absolute_error: 0.0397 - categorical_accuracy: 0.9749 - val_loss: 8.5268 - val_mean_absolute_error: 0.4227 - val_categorical_accuracy: 0.5785\n",
      "Epoch 4: early stopping\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [13], line 122\u001b[0m\n\u001b[1;32m    120\u001b[0m v_c \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mto_categorical(val_label)\n\u001b[1;32m    121\u001b[0m CW \u001b[38;5;241m=\u001b[39m classes_weight(train_label)\n\u001b[0;32m--> 122\u001b[0m model1 \u001b[38;5;241m=\u001b[39m \u001b[43mlearning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtr_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCW\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [13], line 44\u001b[0m, in \u001b[0;36mlearning\u001b[0;34m(train_i, train_l, val_i, val_l, C_weight)\u001b[0m\n\u001b[1;32m     41\u001b[0m API_model\u001b[38;5;241m.\u001b[39mfit(train_i, train_l,validation_data\u001b[38;5;241m=\u001b[39m(val_i, val_l), batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     42\u001b[0m               shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, callbacks\u001b[38;5;241m=\u001b[39m[CP, ES], class_weight\u001b[38;5;241m=\u001b[39mC_weight)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# round(API_model.optimizer.learning_rate,5)\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mplot(API_model\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     45\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(API_model\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     46\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss graph\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras import optimizers,metrics\n",
    "from tensorflow.keras.callbacks import Callback, ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
    "from tensorflow.keras.layers import BatchNormalization, Flatten, Dense, Dropout, Input, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "# class LearningRatePrinter(Callback):\n",
    "#     def on_epoch_end(self, epoch, logs=None):\n",
    "#         learning_rate = backend(self.model.optimizer.lr)\n",
    "#         print(f'Epoch {epoch + 1}: Learning rate is {learning_rate}')\n",
    "\n",
    "def xcept(images):\n",
    "    API_model = Xception(include_top=False, weights='HDF5/xception_weights_tf_dim_ordering_tf_kernels_notop.h5', input_tensor=None,\n",
    "                         input_shape=(images.shape[1:]), pooling=None, classes=2)\n",
    "    x = API_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    output = Dense(2, activation='softmax')(x)\n",
    "    model = Model(inputs=API_model.inputs, outputs=output)\n",
    "    return model\n",
    "\n",
    "def learning(train_i, train_l,val_i, val_l, C_weight):\n",
    "    API_model = xcept(train_i)\n",
    "    adam_w = tf.keras.optimizers.Adam()\n",
    "    # API_model.summary()\n",
    "    API_model.compile(loss=\"categorical_crossentropy\", optimizer=adam_w,\n",
    "                      metrics = [metrics.mae, metrics.categorical_accuracy])\n",
    "    # round(API_model.optimizer.learning_rate,5)\n",
    "    # tensorboard = TensorBoard(log_dir = \"PreTrain_log/240719_16_35/\", histogram_freq = 1, write_graph=True)\n",
    "    # LRP = LearningRatePrinter()\n",
    "    CP = ModelCheckpoint(\"HDF5/MT_240802.hdf5\", monitor='loss', save_best_only=True)\n",
    "    ES = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3, verbose=1, mode=\"min\",\n",
    "                       restore_best_weights=True)\n",
    "    # LRS = LearningRateScheduler(scheduler)\n",
    "    API_model.fit(train_i, train_l,validation_data=(val_i, val_l), batch_size=256, epochs=100, verbose=1,\n",
    "                  shuffle=True, callbacks=[CP, ES], class_weight=C_weight)\n",
    "    # round(API_model.optimizer.learning_rate,5)\n",
    "    plt.plot(API_model.history['loss'])\n",
    "    plt.plot(API_model.history['val_loss'])\n",
    "    plt.title('Loss graph')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(['train','val'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(API_model.history['accuracy'])\n",
    "    plt.plot(API_model.history['val_accuracy'])\n",
    "    plt.title('Accuracy graph')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(['train','val'], loc='upper left')\n",
    "    plt.show()\n",
    "    return API_model\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch<3:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr*1e-02\n",
    "\n",
    "def classes_weight(label):\n",
    "    # a=list(label).count(0)\n",
    "    # b=list(label).count(1)\n",
    "    # c=list(label).count(2)\n",
    "    # d=list(label).count(3)\n",
    "    # print('0= ', a, '1= ',b, '2= ',c, '3= ',d)\n",
    "    # weight_0 = (1/a)*label.shape[0]/4\n",
    "    # weight_1 = (1/b)*label.shape[0]/4\n",
    "    # weight_2 = (1/c)*label.shape[0]/4\n",
    "    # weight_3 = (1/d)*label.shape[0]/4\n",
    "\n",
    "    # CW = {0:weight_0,\n",
    "    #       1:weight_1,\n",
    "    #       2:weight_2,\n",
    "    #       3:weight_3,}\n",
    "\n",
    "    # print('Weight for Classes 0: {:.2f}'.format(weight_0),\n",
    "    #       'Weight for Classes 1: {:.2f}'.format(weight_1),\n",
    "    #       'Weight for Classes 2: {:.2f}'.format(weight_2),\n",
    "    #       'Weight for Classes 3: {:.2f}'.format(weight_3),)\n",
    "\n",
    "    a=list(label).count(0)\n",
    "    b=list(label).count(1)\n",
    "    print('0= ', a, '1= ',b)\n",
    "\n",
    "    weight_0 = (1/a)*label.shape[0]/2\n",
    "    weight_1 = (1/b)*label.shape[0]/2\n",
    "\n",
    "    CW = {0:weight_0,\n",
    "          1:weight_1}\n",
    "    print('Weight for Classes 0: {:.2f}'.format(weight_0),\n",
    "          'Weight for Classes 1: {:.2f}'.format(weight_1))\n",
    "    return CW\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # tr_img_data = np.load(\"npys/For_Pretraining/Train_imgs.npy\")\n",
    "    # tr_label_data = np.load(\"npys/For_Pretraining/Train_labels.npy\")\n",
    "    # v_img_data = np.load(\"npys/For_Pretraining/Val_imgs.npy\")\n",
    "    # v_label_data = np.load(\"npys/For_Pretraining/Val_labels.npy\")\n",
    "#     np.save(\"npys/LUMIC_Train_imgs.npy\", imgs)\n",
    "#     np.save(\"npys/LUMIC_Train_labels.npy\", labels)\n",
    "    print('*'*30)\n",
    "    print('Loading Dataset')\n",
    "    print('*'*30)\n",
    "    img_data = np.load(\"npys/Total_imgs.npy\")\n",
    "    label_data = np.load(\"npys/Total_imgs_labels.npy\")\n",
    "    print('*'*30)\n",
    "    print('Complete Load Dataset')\n",
    "    print('*'*30)\n",
    "    print(img_data.shape[1:])\n",
    "    train_img, val_img, train_label, val_label = train_test_split(img_data, label_data, test_size = 0.3, random_state=602625)\n",
    "    print(\"Train: \",train_img.shape, \"Val: \",val_img.shape)\n",
    "    tr_c = tf.keras.utils.to_categorical(train_label)\n",
    "    v_c = tf.keras.utils.to_categorical(val_label)\n",
    "    CW = classes_weight(train_label)\n",
    "    model1 = learning(train_img, tr_c, val_img, v_c, CW)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ca3231c-2cec-47c2-abc5-b78d59e47877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001\n"
     ]
    }
   ],
   "source": [
    "print(1e-04)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
